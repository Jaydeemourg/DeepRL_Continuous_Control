{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "This notebook uses the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Import necessary packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from DDPG_agent import Agent\n",
    "from itertools import count\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Start the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='./Reacher_Linux/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# Information about the environment.\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Instantiate the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = len(env_info.agents)\n",
    "agent = Agent(state_size=state_size, action_size=action_size, num_agents=num_agents, random_seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=1000, queue=100):\n",
    "    scores_window = deque(maxlen=queue)\n",
    "    scores_all = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        scores = np.zeros(num_agents)\n",
    "        while True:\n",
    "            actions = agent.act(states)                        # select an action (for each agent)\n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            scores += rewards                                  # update the score (for each agent)\n",
    "            states = next_states                               # roll over states to next time step\n",
    "            if np.any(dones):                                  # exit loop if episode finished\n",
    "                break\n",
    "\n",
    "        scores_window.append(np.mean(scores))\n",
    "        scores_all.append(np.mean(scores))\n",
    "        \n",
    "        print('Episode {}  Score: {:.3f}  Average Score: {:.3f}'.format(\n",
    "                i_episode, np.mean(scores), np.mean(scores_window)))\n",
    "\n",
    "        if np.mean(scores_window)>=30.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.3f}'.format(\n",
    "                i_episode, np.mean(scores_window)))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break\n",
    "\n",
    "    return scores_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train DDPG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1  Score: 0.769  Average Score: 0.769\n",
      "Episode 2  Score: 0.998  Average Score: 0.883\n",
      "Episode 3  Score: 0.920  Average Score: 0.896\n",
      "Episode 4  Score: 0.894  Average Score: 0.895\n",
      "Episode 5  Score: 0.963  Average Score: 0.909\n",
      "Episode 6  Score: 1.221  Average Score: 0.961\n",
      "Episode 7  Score: 1.146  Average Score: 0.987\n",
      "Episode 8  Score: 1.457  Average Score: 1.046\n",
      "Episode 9  Score: 1.178  Average Score: 1.061\n",
      "Episode 10  Score: 1.663  Average Score: 1.121\n",
      "Episode 11  Score: 1.453  Average Score: 1.151\n",
      "Episode 12  Score: 2.437  Average Score: 1.258\n",
      "Episode 13  Score: 2.346  Average Score: 1.342\n",
      "Episode 14  Score: 3.020  Average Score: 1.462\n",
      "Episode 15  Score: 2.837  Average Score: 1.554\n",
      "Episode 16  Score: 3.817  Average Score: 1.695\n",
      "Episode 17  Score: 3.899  Average Score: 1.825\n",
      "Episode 18  Score: 4.962  Average Score: 1.999\n",
      "Episode 19  Score: 5.912  Average Score: 2.205\n",
      "Episode 20  Score: 6.967  Average Score: 2.443\n",
      "Episode 21  Score: 8.997  Average Score: 2.755\n",
      "Episode 22  Score: 11.270  Average Score: 3.142\n",
      "Episode 23  Score: 14.664  Average Score: 3.643\n",
      "Episode 24  Score: 15.921  Average Score: 4.155\n",
      "Episode 25  Score: 20.428  Average Score: 4.806\n",
      "Episode 26  Score: 23.585  Average Score: 5.528\n",
      "Episode 27  Score: 24.519  Average Score: 6.231\n",
      "Episode 28  Score: 25.516  Average Score: 6.920\n",
      "Episode 29  Score: 28.264  Average Score: 7.656\n",
      "Episode 30  Score: 27.488  Average Score: 8.317\n",
      "Episode 31  Score: 30.423  Average Score: 9.030\n",
      "Episode 32  Score: 31.775  Average Score: 9.741\n",
      "Episode 33  Score: 32.131  Average Score: 10.420\n",
      "Episode 34  Score: 34.607  Average Score: 11.131\n",
      "Episode 35  Score: 36.378  Average Score: 11.852\n",
      "Episode 36  Score: 36.616  Average Score: 12.540\n",
      "Episode 37  Score: 36.688  Average Score: 13.193\n",
      "Episode 38  Score: 37.401  Average Score: 13.830\n",
      "Episode 39  Score: 36.867  Average Score: 14.421\n",
      "Episode 40  Score: 37.104  Average Score: 14.988\n",
      "Episode 41  Score: 36.628  Average Score: 15.516\n",
      "Episode 42  Score: 37.090  Average Score: 16.029\n",
      "Episode 43  Score: 36.809  Average Score: 16.513\n",
      "Episode 44  Score: 37.282  Average Score: 16.985\n",
      "Episode 45  Score: 37.186  Average Score: 17.433\n",
      "Episode 46  Score: 37.225  Average Score: 17.864\n",
      "Episode 47  Score: 37.124  Average Score: 18.274\n",
      "Episode 48  Score: 37.230  Average Score: 18.668\n",
      "Episode 49  Score: 37.087  Average Score: 19.044\n",
      "Episode 50  Score: 37.508  Average Score: 19.414\n",
      "Episode 51  Score: 37.094  Average Score: 19.760\n",
      "Episode 52  Score: 37.572  Average Score: 20.103\n",
      "Episode 53  Score: 37.186  Average Score: 20.425\n",
      "Episode 54  Score: 37.287  Average Score: 20.737\n",
      "Episode 55  Score: 36.729  Average Score: 21.028\n",
      "Episode 56  Score: 36.893  Average Score: 21.312\n",
      "Episode 57  Score: 36.670  Average Score: 21.581\n",
      "Episode 58  Score: 36.831  Average Score: 21.844\n",
      "Episode 59  Score: 36.648  Average Score: 22.095\n",
      "Episode 60  Score: 37.310  Average Score: 22.348\n",
      "Episode 61  Score: 38.026  Average Score: 22.605\n",
      "Episode 62  Score: 37.354  Average Score: 22.843\n",
      "Episode 63  Score: 37.228  Average Score: 23.072\n",
      "Episode 64  Score: 36.577  Average Score: 23.283\n",
      "Episode 65  Score: 37.510  Average Score: 23.502\n",
      "Episode 66  Score: 36.473  Average Score: 23.698\n",
      "Episode 67  Score: 36.133  Average Score: 23.884\n",
      "Episode 68  Score: 37.234  Average Score: 24.080\n",
      "Episode 69  Score: 36.802  Average Score: 24.264\n",
      "Episode 70  Score: 37.519  Average Score: 24.454\n",
      "Episode 71  Score: 36.820  Average Score: 24.628\n",
      "Episode 72  Score: 37.048  Average Score: 24.800\n",
      "Episode 73  Score: 36.133  Average Score: 24.956\n",
      "Episode 74  Score: 34.637  Average Score: 25.087\n",
      "Episode 75  Score: 35.210  Average Score: 25.222\n",
      "Episode 76  Score: 35.806  Average Score: 25.361\n",
      "Episode 77  Score: 35.472  Average Score: 25.492\n",
      "Episode 78  Score: 36.613  Average Score: 25.635\n",
      "Episode 79  Score: 36.120  Average Score: 25.767\n",
      "Episode 80  Score: 36.027  Average Score: 25.896\n",
      "Episode 81  Score: 36.650  Average Score: 26.028\n",
      "Episode 82  Score: 36.004  Average Score: 26.150\n",
      "Episode 83  Score: 35.904  Average Score: 26.268\n",
      "Episode 84  Score: 35.682  Average Score: 26.380\n",
      "Episode 85  Score: 35.538  Average Score: 26.487\n",
      "Episode 86  Score: 35.892  Average Score: 26.597\n",
      "Episode 87  Score: 36.443  Average Score: 26.710\n",
      "Episode 88  Score: 36.419  Average Score: 26.820\n",
      "Episode 89  Score: 36.270  Average Score: 26.926\n",
      "Episode 90  Score: 35.274  Average Score: 27.019\n",
      "Episode 91  Score: 35.482  Average Score: 27.112\n",
      "Episode 92  Score: 34.192  Average Score: 27.189\n",
      "Episode 93  Score: 34.524  Average Score: 27.268\n",
      "Episode 94  Score: 36.023  Average Score: 27.361\n",
      "Episode 95  Score: 36.498  Average Score: 27.457\n",
      "Episode 96  Score: 35.954  Average Score: 27.546\n",
      "Episode 97  Score: 36.469  Average Score: 27.638\n",
      "Episode 98  Score: 36.149  Average Score: 27.725\n",
      "Episode 99  Score: 36.333  Average Score: 27.812\n",
      "Episode 100  Score: 35.758  Average Score: 27.891\n",
      "Episode 101  Score: 36.496  Average Score: 28.248\n",
      "Episode 102  Score: 35.975  Average Score: 28.598\n",
      "Episode 103  Score: 36.494  Average Score: 28.954\n",
      "Episode 104  Score: 36.695  Average Score: 29.312\n",
      "Episode 105  Score: 36.240  Average Score: 29.665\n",
      "Episode 106  Score: 36.648  Average Score: 30.019\n",
      "\n",
      "Environment solved in 106 episodes!\tAverage Score: 30.019\n"
     ]
    }
   ],
   "source": [
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "plt.subplot(1, 1, 1)  # 111\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend()\n",
    "plt.savefig('score_per_episode_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load trained agent and watch its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 33.74699924569577\n"
     ]
    }
   ],
   "source": [
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = agent.act(states)                        # select an action (for each agent)\n",
    "    # actions = np.clip(actions, -1, 1)                # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
